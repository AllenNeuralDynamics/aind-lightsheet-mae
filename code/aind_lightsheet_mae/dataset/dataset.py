"""
Defines the neuron data loader
"""

from glob import glob
from pathlib import Path
from typing import Generator, List, Optional, Tuple

import lightning as L
import numpy as np
import torch
from natsort import natsorted
from torch.utils.data import DataLoader, Dataset, get_worker_info

from .._shared.types import ArrayLike, PathLike
from ..io._io import N5Reader
from .utils import extract_data, validate_input_path


def gen_slices(
    arr_shape: Tuple[int, ...],
    block_shape: Tuple[int, ...],
    dimension: Optional[int] = 0,
    start_shape: Optional[List[int]] = None,
) -> Generator:
    """
    Generate a series of slices that can be used to traverse an array in
    blocks of a given shape.

    The method generates tuples of slices, each representing a block of
    the array. The blocks are generated by iterating over the array in
    steps of the block shape along each dimension.

    Parameters
    ----------
    arr_shape : tuple of int
        The shape of the array to be sliced.

    block_shape : tuple of int
        The desired shape of the blocks. This should be a tuple of integers
        representing the size of each dimension of the block. The length of
        `block_shape` should be equal to the length of `arr_shape`.
        If the array shape is not divisible by the block shape along a dimension,
        the last slice along that dimension is truncated.

    Returns
    -------
    generator of tuple of slice
        A generator yielding tuples of slices. Each tuple can
        be used to index the input array.
    """
    if start_shape is None:
        start_shape = [0] * len(arr_shape)

    if len(arr_shape) != len(block_shape) or len(arr_shape) != len(
        start_shape
    ):
        raise Exception("array shape and block shape have different lengths")

    for idx in range(len(arr_shape)):
        if start_shape[idx] >= arr_shape[idx] or start_shape[idx] < 0:
            raise ValueError("Please, verify your start shape")

    def _slice_along_dim(dim: int) -> Generator:
        """A helper generator function that slices along one dimension."""
        # Base case: if the dimension is beyond the last one, return an empty tuple
        if dim >= len(arr_shape):
            yield ()
        else:
            # Iterate over the current dimension in steps of the block size
            for i in range(start_shape[dim], arr_shape[dim], block_shape[dim]):
                # Calculate the end index for this block
                end_i = min(i + block_shape[dim], arr_shape[dim])
                # Generate slices for the remaining dimensions
                for rest in _slice_along_dim(dim + 1):
                    yield (slice(i, end_i),) + rest

    # Start slicing along the first dimension
    return _slice_along_dim(dim=dimension)


def __convert_to_torch(data: ArrayLike):
    """
    Converts an array from numpy to torch
    if necessary

    Parameters
    ----------
    data: ArrayLike
        Image data

    Returns
    -------
    torch.Tensor
        Image data in torch tensor format
    """
    if isinstance(data, np.ndarray):
        data = torch.from_numpy(data)

    return data


class ZarrCustomBatch:
    """
    Custom zarr batch object to manage pin memory
    """

    def __init__(
        self,
        batched_image: List[torch.Tensor],
        batched_mask: List[torch.Tensor],
    ):
        """
        Init method

        """
        self.image = torch.stack(batched_image)
        self.mask = torch.stack(batched_mask)

    def pin_memory(self):
        """
        Custom pin memory for GPU loading optimization
        """
        self.image = self.batched_image.pin_memory()
        self.mask = self.batched_mask.pin_memory()
        return self


def collate_fn(
    batch: ArrayLike,
    prediction_chunksize: Optional[Tuple[int, ...]] = (64, 64, 64),
) -> ArrayLike:
    """
    batch: ArrayLike
        Batch of data

    prediction_chunksize: Optional[Tuple[int, ...]]
        Prediction chunksize we will use to partition
        the read blocks and return data

    Returns
    -------
    Tuple[ArrayLike, ArrayLike]
        Tuple with the partitioned image data and
        the mask
    """
    batched_image = []
    batched_mask = []

    for image, mask in batch:
        image = __convert_to_torch(image)
        mask = __convert_to_torch(mask)
        len_chunks = len(prediction_chunksize)

        if image.shape != mask.shape:
            raise ValueError(
                f"Please, check your image shape {image.shape} and your mask shape {mask.shape}"
            )

        for chunked_slice in gen_slices(
            arr_shape=image.shape,
            block_shape=prediction_chunksize,
            dimension=0,
        ):
            patched_image = image[chunked_slice]
            patched_mask = image[chunked_slice]

            if patched_image.shape != prediction_chunksize:
                # n-dim slices - batches 2D - 3D data
                min_slices = tuple(
                    slice(
                        0,
                        min(
                            prediction_chunksize[idx], patched_image.shape[idx]
                        ),
                    )
                    for idx in range(len_chunks)
                )

                image_zeros = torch.zeros(
                    size=prediction_chunksize, dtype=image.dtype
                )
                mask_zeros = torch.zeros(
                    size=prediction_chunksize, dtype=mask.dtype
                )

                # Filling zeros array with batch data
                image_zeros[min_slices] = patched_image[min_slices]
                mask_zeros[min_slices] = patched_mask[min_slices]

                patched_image = image_zeros
                patched_mask = mask_zeros

            batched_image.append(patched_image)
            batched_mask.append(patched_mask)

    return ZarrCustomBatch(batched_image, batched_mask)


class NeuronDataset(Dataset):
    def __init__(
        self,
        folder_dir: PathLike,
        prediction_chunksize: str,
        output_dtype: type,
        n5_dataset: Optional[str] = "volume",
        transform=None,
        augmentations=None,
    ) -> None:
        self.folder_dir = validate_input_path(folder_dir)
        self.prediction_chunksize = prediction_chunksize
        self.output_dtype = output_dtype
        self.images = tuple(
            natsorted(
                glob(
                    f"{self.folder_dir}/{self.prediction_chunksize}/block_*/chunks/*.npy"
                )
            )
        )
        self.masks = tuple(
            natsorted(
                glob(
                    f"{self.folder_dir}/{self.prediction_chunksize}/block_*/masks/*.npy"
                )
            )
        )
        self.n5_dataset = n5_dataset
        self.transform = transform
        self.augmentations = augmentations

        if len(self.masks) != len(self.images):
            raise ValueError(
                f"Please, check your images. Images {len(self.images)} - Masks {len(self.masks)}"
            )

    def __read_image(self, index: int):
        """
        Reads an N5 image

        Parameters
        ----------
        index: int
            Internal index for the image block
        """
        image = None
        mask = None

        extension = Path(self.images[index]).suffix
        if extension == ".npy":
            # Read numpy array
            image = np.load(self.images[index]).astype(self.output_dtype)
            mask = np.load(self.masks[index]).astype(self.output_dtype)

        elif extension == ".n5":
            image = extract_data(
                N5Reader(self.images[index])
                .as_numpy_array(self.n5_dataset)
                .astype(self.output_dtype)
            )

            mask = extract_data(
                N5Reader(self.masks[index])
                .as_numpy_array(self.n5_dataset)
                .astype(self.output_dtype)
            )

        # Expanding dimensions in first axis for grayscale images
        if len(image.shape) == 3:
            image = np.expand_dims(image, axis=0)
            mask = np.expand_dims(mask, axis=0)

        return torch.from_numpy(image), torch.from_numpy(mask)

    def __getitem__(self, index: int):
        # worker_info = get_worker_info()
        image, mask = self.__read_image(index)

        if self.transform is not None:
            # print(self.transform)
            image = self.transform(image)

        if self.augmentations is not None:
            image, mask = self.augmentations(image, mask)

        if self.transform is not None:
            # print(self.transform)
            image = self.transform(image)

        return image, mask

    def __len__(self):
        return len(self.masks)


class NeuronDataModule(L.LightningDataModule):
    def __init__(
        self,
        train_path,
        validation_path,
        prediction_chunksize,
        output_dtype,
        batch_size,
        n5_dataset: str = "volume",
        transform=None,
        num_workers: int = 0,
    ):
        super().__init__()
        self.train_path = train_path
        self.validation_path = validation_path
        self.prediction_chunksize = prediction_chunksize
        self.output_dtype = output_dtype
        self.n5_dataset = n5_dataset
        self.batch_size = batch_size
        self.transform = transform
        self.num_workers = num_workers

    def setup(self, stage=None):
        self.train_dataset = NeuronDataset(
            folder_dir=self.train_path,
            prediction_chunksize=self.prediction_chunksize,
            output_dtype=self.output_dtype,
            n5_dataset=self.n5_dataset,
        )

        if self.transform is not None:
            self.train_dataset.transform = self.transform

        self.validation_dataset = NeuronDataset(
            folder_dir=self.validation_path,
            prediction_chunksize=self.prediction_chunksize,
            output_dtype=self.output_dtype,
            n5_dataset=self.n5_dataset,
        )

    def train_dataloader(self):
        return DataLoader(
            self.train_dataset,
            batch_size=self.batch_size,
            num_workers=self.num_workers,
            shuffle=True,
            self.train_dataset, batch_size=self.batch_size, shuffle=True
        )

    def training_epoch_end(self, outputs) -> None:
        loss = sum(output["loss"] for output in outputs) / len(outputs)
        print(loss)

    def val_dataloader(self):
        return DataLoader(
            self.validation_dataset,
            batch_size=self.batch_size,
            num_workers=self.num_workers,
        )

    def predict_dataloader(self):
        return DataLoader(
            self.validation_dataset,
            batch_size=self.batch_size,
            shuffle=False,
            num_workers=self.num_workers,
        )

    def predict_dataloader(self):
        return DataLoader(
            self.validation_dataset, batch_size=self.batch_size, shuffle=False
        )


def check_dataloader():
    """
    Main function to check data loader
    """
    import matplotlib.pyplot as plt

    BASE_PATH = "/Users/camilo.laiton/repositories/Neuratt/data/train_dataset"
    neuron_dataset = NeuronDataset(
        folder_dir=BASE_PATH,
        prediction_chunksize=(64, 64, 64),
        output_dtype=np.int32,
        n5_dataset="volume",
    )

    neuron_loader = DataLoader(
        dataset=neuron_dataset,
        batch_size=16,
        num_workers=0,
        # collate_fn=collate_fn,
    )

    # n_plots = 3
    for idx, (image_batch, mask_batch) in enumerate(neuron_loader):
        print(f"[{idx}] Image {image_batch.shape} - Mask {mask_batch.shape}")

        # if idx < n_plots:
        #     middle_z = image.shape[1] // 2
        #     print(f"Plotting slice {middle_z}")
        #     fig, (ax1, ax2) = plt.subplots(1, 2)

        #     ax1.imshow(image[0, middle_z, :, :], cmap="gray")
        #     ax1.set_title(f"Image {idx}")

        #     # Plot the second image on the right subplot
        #     ax2.imshow(mask[0, middle_z, :, :], cmap="gray")
        #     ax2.set_title(f"Mask {idx}")

        #     # Adjust spacing between subplots
        #     plt.subplots_adjust(wspace=0.3)

        #     # Show the figure
        #     plt.show()


if __name__ == "__main__":
    check_dataloader()